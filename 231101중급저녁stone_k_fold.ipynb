{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1CfIRCY3C_SHrK1lwNHi4QO0r-0-f2bP9","authorship_tag":"ABX9TyMa0VOqVtA6KOMwmQGcjg2C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aIzw3Ppzr8X7","executionInfo":{"status":"ok","timestamp":1698839868886,"user_tz":-540,"elapsed":45609,"user":{"displayName":"Wholesome Route","userId":"01578778706005799823"}},"outputId":"2ffe7daa-1a36-47e6-b9ae-f0461024492f"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7c621569bac0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 12ms/step - loss: 0.4182 - accuracy: 0.8810\n","2/2 [==============================] - 0s 8ms/step - loss: 1.1090 - accuracy: 0.7857\n","2/2 [==============================] - 0s 10ms/step - loss: 0.4765 - accuracy: 0.8333\n","2/2 [==============================] - 0s 9ms/step - loss: 1.0415 - accuracy: 0.8537\n","2/2 [==============================] - 0s 14ms/step - loss: 0.3409 - accuracy: 0.9268\n","정확도: [0.8809523582458496, 0.7857142686843872, 0.8333333134651184, 0.8536585569381714, 0.9268292784690857]\n","정확도 평균: 0.8560975551605224\n"]}],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Wed Nov  1 20:04:50 2023\n","\n","@author: Administrator\n","\"\"\"\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score\n","\n","import pandas as pd\n","\n","# 데이터를 입력합니다.\n","df = pd.read_csv('/content/drive/MyDrive/sonar3.csv', header=None)\n","\n","# 음파 관련 속성을 X로, 광물의 종류를 y로 저장합니다.\n","X = df.iloc[:,0:60]\n","y = df.iloc[:,60]\n","#몇 겹으로 나눌 것인지를 정합니다.\n","k=5\n","\n","#KFold 함수를 불러옵니다. 분할하기 전에 샘플이 치우치지 않도록 섞어 줍니다.\n","kfold = KFold(n_splits=k, shuffle=True, random_state= 42)\n","\n","#정확도가 채워질 빈 리스트를 준비합니다.\n","acc_score = []\n","\n","def model_fn():\n","    model = Sequential() #딥러닝 모델의 구조를 시작합니다.\n","    model.add(Dense(24, input_dim=60, activation='relu'))\n","    model.add(Dense(10, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","    return model\n","\n","#K겹 교차 검증을 이용해 k번의 학습을 실행합니다.\n","for train_index , test_index in kfold.split(X):  # for문에 의해서 k번 반복합니다. spilt()에 의해 k개의 학습셋, 테스트셋으로 분리됩니다.\n","    X_train , X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n","    y_train , y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","    model = model_fn()\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    history=model.fit(X_train, y_train, epochs=200, batch_size=10, verbose=0)\n","\n","    accuracy = model.evaluate(X_test, y_test)[1]  #정확도를 구합니다.\n","    acc_score.append(accuracy)  #정확도 리스트에 저장합니다.\n","\n","#k번 실시된 정확도의 평균을 구합니다.\n","avg_acc_score = sum(acc_score)/k\n","\n","#결과를 출력합니다.\n","print('정확도:', acc_score)\n","print('정확도 평균:', avg_acc_score)"]}]}